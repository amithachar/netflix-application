#### Now youâ€™re thinking like someone building a real platform.
####If you canâ€™t observe it, you donâ€™t control it.

####Weâ€™ll add Prometheus (metrics collector) and Grafana (visualization UI) to your GKE cluster the clean way.

#### Weâ€™ll use Helm. Thatâ€™s the professional method.

ğŸ§  What Weâ€™re Installing

#### Weâ€™ll install:

#### kube-prometheus-stack

#### That bundle includes:

#### Prometheus

#### Grafana

#### Node Exporter

#### kube-state-metrics

#### Alertmanager

#### It gives:

#### Node CPU, memory, disk

#### Pod metrics

#### Deployment metrics

#### Cluster health

#### Prebuilt dashboards

## ğŸš€ Step 1 â€” Install Helm

#### On your Jenkins VM (or wherever kubectl works):

```
curl https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 | bash
```

### Verify:

```
helm version
```

## ğŸš€ Step 2 â€” Add Prometheus Helm Repo
```
helm repo add prometheus-community https://prometheus-community.github.io/helm-charts
helm repo update
```
## ğŸš€ Step 3 â€” Create Monitoring Namespace
```
kubectl create namespace monitoring
```
## ğŸš€ Step 4 â€” Install kube-prometheus-stack
```
helm install monitoring prometheus-community/kube-prometheus-stack \
  --namespace monitoring
```

### Wait 2â€“3 minutes.

### Check pods:
```
kubectl get pods -n monitoring
```

You should see:

prometheus

grafana

node-exporter

kube-state-metrics

## ğŸš€ Step 5 â€” Expose Grafana

### By default Grafana is internal.

### Expose it via LoadBalancer:
```
kubectl patch svc monitoring-grafana \
  -n monitoring \
  -p '{"spec": {"type": "LoadBalancer"}}'
```

### Then:
```
kubectl get svc -n monitoring
```

### Wait for EXTERNAL-IP.

### Open in browser:

```
http://<external-ip>
```

## ğŸ” Grafana Login

### Default:

### Username:
```
admin
```

### Password:
```
kubectl get secret --namespace monitoring monitoring-grafana \
  -o jsonpath="{.data.admin-password}" | base64 --decode ; echo
```

## ğŸ§  What Youâ€™ll See

#### Inside Grafana â†’ Dashboards â†’ Manage

### Look for:

####  Kubernetes / Compute Resources / Node

####  Kubernetes / Compute Resources / Pod

#### Kubernetes / Compute Resources / Namespace

#### Kubernetes / Cluster Overview

### Those dashboards show:

#### CPU usage

####  Memory usage

#### Network

#### Pod status

#### Node health

## ğŸ§  Architecture After Install
GKE Cluster
 â”œâ”€â”€ Your OTT Pods
 â”œâ”€â”€ Prometheus Pod (scraping metrics)
 â”œâ”€â”€ Node Exporter (collecting node metrics)
 â””â”€â”€ Grafana (visualizing)


####  You now have observability.

#### âš ï¸ Free Tier Warning

####   This stack consumes resources.

#### You may see:

####  4â€“8 extra pods

#### Increased memory usage

#### If your node is e2-micro, it might struggle.

#### If pods stay Pending:
####  You need to scale node.

## ğŸ”¬ Optional (Safer for Small Nodes)

#### If your node is small, install with reduced resource usage:

```
helm install monitoring prometheus-community/kube-prometheus-stack \
  --namespace monitoring \
  --set prometheus.prometheusSpec.resources.requests.memory="256Mi" \
  --set grafana.resources.requests.memory="128Mi"
```

## ğŸ§  Why This Matters

#### Before monitoring:
####  You deploy blindly.

#### After monitoring:
#### You see:

####  CPU spikes

####  Memory pressure

#### Restart loops

#### Node health

#### Now youâ€™re building a real production-ready cluster.

#### If you want next level:

#### Add HPA and watch scaling in Grafana

#### Add alert rules

#### Integrate with Slack

####  Add Loki for logs

####  Youâ€™re stepping into SRE territory now.

####  explain how to set dasboard in grafana for kubernetes monitring

####  Now weâ€™re entering observability philosophy. Good.

#### Grafana is just a window.
####  Prometheus is the brain.
####  Metrics are the truth.

####  If Prometheus is scraping your cluster (via kube-prometheus-stack), Grafana already has most dashboards preloaded.

## Letâ€™s walk through it properly and cleanly.

####  ğŸ§  First Understand the Data Flow
####  Node â†’ node-exporter â†’ Prometheus
#### Pod â†’ kube-state-metrics â†’ Prometheus
#### Prometheus â†’ Grafana â†’ You


### Prometheus collects metrics.
### Grafana visualizes them.

### You donâ€™t â€œcreate monitoring.â€
### You visualize metrics that already exist.

## ğŸš€ Step 1 â€” Open Grafana

### Go to:
```
http://<grafana-external-ip>
```

### Login with:

### Username: admin

### Password: (from secret)

## ğŸš€ Step 2 â€” Check Data Source

### Left sidebar â†’ âš™ï¸ Settings â†’ Data Sources

### You should see:

### Prometheus


### Click it â†’ Test

### It should say:

### Data source is working


### If not, something is wrong with Prometheus.

## ğŸš€ Step 3 â€” Use Prebuilt Kubernetes Dashboards

### kube-prometheus-stack installs dashboards automatically.

### Go to:

### Left Sidebar â†’ Dashboards â†’ Browse

### Search:

### Kubernetes


## You will find:

### Kubernetes / Compute Resources / Node

### Kubernetes / Compute Resources / Pod

### Kubernetes / Compute Resources / Namespace

### Kubernetes / Cluster Overview

### Kubernetes / API Server

## Open:

## ğŸ‘‰ Kubernetes / Compute Resources / Node

### You will see:

### CPU usage per node

### Memory usage

### Filesystem usage

### Network traffic

### Open:

## ğŸ‘‰ Kubernetes / Compute Resources / Pod

### You will see:

### Pod CPU usage

### Pod memory usage

### Restart counts

### Container status

## Thatâ€™s real cluster monitoring.

### ğŸ§  How Dashboards Actually Work

### Each panel runs a PromQL query.

### Example CPU usage query:
```
sum(rate(container_cpu_usage_seconds_total[5m])) by (pod)
```

### That means:
### â€œShow CPU usage per pod over last 5 minutes.â€

### Grafana panels = visual PromQL queries.

## ğŸš€ Step 4 â€” Create Your Own Dashboard

### Letâ€™s create a simple one for your ott-app.

### Click:

### â†’ Dashboard â†’ Add new panel

### Query:

### For CPU usage of your deployment:
```
sum(rate(container_cpu_usage_seconds_total{namespace="default", pod=~"ott-app.*"}[5m]))
```

### Set visualization:

### Time series

### Click Apply.

### You now have custom CPU monitoring for your app.

## ğŸš€ Add Memory Panel

### Add another panel:
```
sum(container_memory_usage_bytes{namespace="default", pod=~"ott-app.*"})
```

### Set unit to:
### Bytes â†’ MB

### Now you can watch memory growth.

## ğŸš€ Node CPU Panel

### Query:
```
sum(rate(node_cpu_seconds_total{mode!="idle"}[5m])) by (instance)
```

### This shows node-level CPU usage.

### ğŸ§  Understanding What You're Watching

### Node dashboard â†’ Infrastructure health
### Pod dashboard â†’ Application health
### Namespace dashboard â†’ Service-level health

### If node CPU spikes â†’ scale nodes
### If pod CPU spikes â†’ scale pods
### If memory spikes â†’ fix app or increase resources

### Monitoring drives scaling decisions.

## ğŸš€ Bonus â€” Add Replica Monitoring

### Query:
```
kube_deployment_status_replicas{deployment="ott-app"}
```

### This shows how many replicas are running.

### If you scale deployment, this graph changes instantly.

## ğŸ§  Real Production Setup

### Production Grafana setup usually includes:

### Node dashboard

### Pod dashboard

### API latency dashboard

### Error rate dashboard

### HPA metrics

### Alert rules

### Monitoring without alerts is only half observability.
